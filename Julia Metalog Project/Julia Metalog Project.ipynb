{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Motivation\n",
    "Metadistributions as discussed in [Keelin (2016)](http://www.metalogdistributions.com/images/The_Metalog_Distributions_-_Keelin_2016.pdf) and earlier papers of his essentially result from expanding the parameters of a distribution as a power series. By choosing carefully which distributions to use it is possible create distributions with high shape flexibility. Keelin initially chooses to use the logistic distribution because its quantile function\n",
    "$$Q(y;\\mu,s) = \\mu + s ln\\left( \\frac{y}{1-y} \\right), 0<y<1$$\n",
    "\n",
    "is linear in its parameters, where $\\mu$ is the mean, median, and mode, and $s$ is proportional to the standard deviation $\\sigma = \\frac{s \\pi}{\\sqrt{3}}$. Following expansion of $\\mu$ and $s$ in cumulative probability with real parameters $a_i$\n",
    "\n",
    "$$\\mu = a_1 + a_4 (y - 0.5) + a_5 (y - 0.5)^2 + a_7 (y - 0.5)^3 + a_9 (y - 0.5)^4 + ...,$$\n",
    "$$s = a_2 + a_3 (y - 0.5) + a_6 (y - 0.5)^2 + a_8 (y - 0.5)^3 + a_{10}(y - 0.5)^4 + ...,$$\n",
    "\n",
    "we may use linear least squares to fit the $a_i$'s to data. As additional terms are added to the expansions, the shape flexibility of the metalogistic distribution quickly approaches the upper limit for all distributions.\n",
    "\n",
    "The shape flexibility given by this methodology is potentially useful within mathematical finance for two main reasons. \n",
    "\n",
    "Attention has been increasingly paid to the fact that many quantities of interest which describe the behaviour of financial markets over the long term have fat tailed distributions. Given that probabilistic models which utilize moment based descriptions - such as the standard deviation for risk measurment - are highly sensitive to the distributional tails, having a precisely tuned tail to the distribution within these models can make a large difference to both their utility and their viability.\n",
    "\n",
    "The parameter based shape flexibility can be also used to create a family of information manifolds. A practical application of this is the usage of recurrent neural networks to continuously vary the parameters of the distribution across a period of time to allow the generation of stochastic processes with wildly different characteristics and arbitrary dependence structures provided by the maintainence of long term dependence within recurrent neural networks such as long short-term memory networks.\n",
    "\n",
    "It is from these and other motivations I have pursued in some time outside my studies to the construction of multivariate metadistributions, one of which is shown below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Progress\n",
    "\n",
    "The single variable Gumbel distribution has CDF\n",
    "\n",
    "$$F(x,\\mu,\\beta) = \\exp(-\\exp(-(x - \\mu)/\\beta))$$\n",
    "\n",
    "which one of the Gumbel distributions multivariate generalisations may have a CDF taking the form\n",
    "\n",
    "$$F(x,\\mu,\\beta) = \\exp \\left( \\sum_{i} -\\exp \\left( -(x_{i} - \\mu_{i})/\\beta_{i} \\right) \\right)$$\n",
    "\n",
    "So far my investigations have indicated that the luxury of using linear least squares to fit the coefficients of the parameter expansions does not generalise to the mulitvariate setting as can be seen in the formulae for the CDFs of most multivarite distributions, including the above multivariate Gumbel CDF. I continue by instead using nonlinear optimisation techniques, of which I have found success with particle swarm optimisation.\n",
    "\n",
    "This rather simple multivariate Gumbel has difficulties when fitting its expanded moments around the origin as the polynomials are double exponentiated. I am currently in the process of exploring other distributions which may be more suitable as a base for an unbounded multivariate metadistribution. As a result I have tested it primarily on semi-bounded distributions, including these three tests on jointly independent semibounded tailed distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fitting process is observed as additional draws from the distributions are made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](e_metalog_scatter.gif)\n",
    "![image](m_metalog_scatter.gif)\n",
    "![image](p_metalog_scatter.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of initial note is how quickly the error of fit in the tails of the double $Exponential(\\lambda = 2)$ vanishes. The error surface displayed here begins at $(20,20)$ which is at the $~99.75$ percentile for this distribution. In the region $ 20 < X < 40$ , $20 < Y < 40$ the error after $n = 60$ is close to $10^{-4}$ \n",
    "\n",
    "Despite the inherently more difficult to fit Pareto distribution we can see in its near tail a relatively close convergence to the true distributional values.\n",
    "\n",
    "These beginning results are being used to direct my further investigation into methods for allowing smoother manipulation with faster optimisation and closer fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions, Plots, Flux, TensorOperations, LinearAlgebra, MultinomialSeries, Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Functions for calculation of tensor eigenvalues gathered from the library TensorFactorizations.jl\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function tensoreig(A, a, b; chis=nothing, eps=0, return_error=false,\n",
    "                   print_error=false, break_degenerate=false,\n",
    "                   degeneracy_eps=1e-6, norm_type=:frobenius,\n",
    "                   hermitian=false)\n",
    "    # Create the matrix and decompose it.\n",
    "    A, shp_a, shp_b = to_matrix(A, a, b; return_tensor_shape=true)\n",
    "    if hermitian\n",
    "        A = Hermitian((A+A')/2)\n",
    "    end\n",
    "    fact = eigen(A)\n",
    "    E, U = fact.values, fact.vectors\n",
    "    # Sort the by largest magnitude eigenvalue first.\n",
    "    perm = sortperm(abs.(E), rev=true)\n",
    "    if perm != collect(1:length(E))\n",
    "        E = E[perm]\n",
    "        U = U[:,perm]\n",
    "    end\n",
    "\n",
    "    # Find the dimensions to truncate to and the error caused in doing so.\n",
    "    chi, error = find_trunc_dim(E, chis, eps, break_degenerate, degeneracy_eps,\n",
    "                                norm_type)\n",
    "\n",
    "    # Truncate\n",
    "    E = E[1:chi]\n",
    "    U = U[:,1:chi]\n",
    "\n",
    "    if print_error\n",
    "        println(\"Relative truncation error ($norm_type norm) in eig: $error\")\n",
    "    end\n",
    "\n",
    "    # Reshape U to a tensor with a shape matching the shape of A and\n",
    "    # return.\n",
    "    dim = size(E)[1]\n",
    "    U_tens = reshape(U, shp_a..., dim)\n",
    "    retval = (E, U_tens)\n",
    "    if return_error\n",
    "        retval = (retval..., error)\n",
    "    end\n",
    "    return retval\n",
    "end\n",
    "\n",
    "\n",
    "function to_matrix(A, a, b; return_tensor_shape=false)\n",
    "    # Make sure a and b are Arrays.\n",
    "    if isa(a, Number)\n",
    "        a = [a]\n",
    "    elseif !isa(a, Array)\n",
    "        a = collect(a)\n",
    "    end\n",
    "    if isa(b, Number)\n",
    "        b = [b]\n",
    "    elseif !isa(b, Array)\n",
    "        b = collect(b)\n",
    "    end\n",
    "\n",
    "    # Permute the indices of A to the right order\n",
    "    perm = vcat(a, b)\n",
    "    A = tensorcopy(A, collect(1:ndims(A)), perm)\n",
    "    # The lists shp_a and shp_b list the dimensions of the bonds in a and b\n",
    "    shp = size(A)\n",
    "    shp_a = shp[1:length(a)]\n",
    "    shp_b = shp[end+1-length(b):end]\n",
    "\n",
    "    # Compute the dimensions of the the matrix that will be formed when\n",
    "    # indices of a and b are joined together.\n",
    "    dim_a = prod(shp_a)\n",
    "    dim_b = prod(shp_b)\n",
    "\n",
    "    A = reshape(A, dim_a, dim_b)\n",
    "\n",
    "    if return_tensor_shape\n",
    "        return A, shp_a, shp_b\n",
    "    else\n",
    "        return A\n",
    "    end\n",
    "end\n",
    "\n",
    "function find_trunc_dim(v, chis, eps,\n",
    "                        break_degenerate=false, degeneracy_eps=1e-6,\n",
    "                        norm_type=:frobenius)\n",
    "    # Put chis in a standard format.\n",
    "    chis = format_trunc_chis(v, chis, eps)\n",
    "    v = abs.(v)\n",
    "    if !issorted(v, rev=true)\n",
    "        sort!(v, rev=true)\n",
    "    end\n",
    "\n",
    "    if norm_type==:frobenius\n",
    "        v = v.^2\n",
    "        eps = eps^2\n",
    "    elseif norm_type == :trace\n",
    "        # Nothing to be done\n",
    "    else\n",
    "        throw(ArgumentError(\"Unknown norm_type $norm_type.\"))\n",
    "    end\n",
    "    sum_all = sum(v)\n",
    "    # Find the smallest chi for which the error is small enough.\n",
    "    # If none is found, use the largest chi.\n",
    "    if sum_all != 0\n",
    "        for i in 1:length(chis)\n",
    "            chi = chis[i]\n",
    "            if !break_degenerate\n",
    "                # Make sure that we don't break degenerate singular values by\n",
    "                # including one but not the other by decreasing chi if\n",
    "                # necessary.\n",
    "                while 0 < chi < length(v)\n",
    "                    last_in = v[chi]\n",
    "                    last_out = v[chi+1]\n",
    "                    rel_diff = abs(last_in - last_out)/last_in\n",
    "                    if rel_diff < degeneracy_eps\n",
    "                        chi -= 1\n",
    "                    else\n",
    "                        break\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            sum_disc = sum(v[chi+1:end])\n",
    "            error = sum_disc/sum_all\n",
    "            if error <= eps\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "        if norm_type==:frobenius\n",
    "            error = sqrt(error)\n",
    "        end\n",
    "    else\n",
    "        error = 0\n",
    "        chi = minimum(chis)\n",
    "    end\n",
    "    return chi, error\n",
    "end\n",
    "\n",
    "\n",
    "function format_trunc_chis(v, chis, eps)\n",
    "    max_dim = length(v)\n",
    "    if chis == nothing\n",
    "        if eps > 0\n",
    "            # Try all possible chis.\n",
    "            chis = collect(1:max_dim)\n",
    "        else\n",
    "            # No truncation.\n",
    "            chis = [max_dim]\n",
    "        end\n",
    "    else\n",
    "        if isa(chis, Number)\n",
    "            # Wrap an individual number in an Array.\n",
    "            chis = [chis]\n",
    "        else\n",
    "            # Make sure chis is an Array, and not, say, a tuple.\n",
    "            chis = collect(chis)\n",
    "        end\n",
    "        if eps == 0\n",
    "            chis = [maximum(chis)]\n",
    "        else\n",
    "            sort!(chis)\n",
    "        end\n",
    "    end\n",
    "    # If some of the chis are larger than max_dim, get rid of them.\n",
    "    for (i, chi) in enumerate(chis)\n",
    "        if chi >= max_dim\n",
    "            chis[i] = max_dim\n",
    "            chis = chis[1:i]\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    return chis\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to test if the tensor of coefficients of the homogenous polynomial used to expand the β parameter is positive definte so \n",
    "# the β > 0 condition is maintained in order to have a feasible probability distribution.\n",
    "\n",
    "function tensor_definiteness(a,vars,degree)\n",
    "    # Create and prepare the tensor to be evaluated\n",
    "    tensor_coefs = ones(vars^degree)\n",
    "            \n",
    "    \n",
    "    ind = 1\n",
    "    for (c,m) in enumerate(eachmultinomial(vars,degree))\n",
    "        bc = multinomial(m)\n",
    "        \n",
    "        if ind === 1 || ind === length(tensor_coefs)\n",
    "            tensor_coefs[ind] = a[c]\n",
    "        else\n",
    "            tensor_coefs[ind:ind+bc-1] = fill(a[c]/bc,bc)\n",
    "        end\n",
    "        ind += bc\n",
    "    end\n",
    "    \n",
    "    tensor_coefs = reshape(tensor_coefs,[vars for c=1:degree]...)\n",
    "\n",
    "    # Find and return the # of negative eigenvalues \n",
    "    eigenvalues = tensoreig(tensor_coefs,collect(1:(degree ÷ 2)),collect((degree ÷ 2)+1:degree))[1]\n",
    "    if !(isa(eigenvalues, Vector{ComplexF64}) || isa(eigenvalues, Vector{ComplexF32}))\n",
    "        # tensoreig does not provide exact values and so need small window below 0\n",
    "        return sum(eigenvalues .<= -1.0*10^-6)#-1.0*10^-6\n",
    "    else\n",
    "        return sum([c.im !== 0.0 for c in eigenvalues])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of data and calculation of its empirical CDF to be used to fit\n",
    "\n",
    "draws = [rand(MvLogNormal([0.,0.],[1. 0.4; 0.4 1.])) for c=1:100]\n",
    "\n",
    "sorted_draws = sort(draws,by=x->x[1])\n",
    "\n",
    "MV_ECDF = Dict{Vector{Float64}, Float64}()\n",
    "\n",
    "l_sorted_draws = length(sorted_draws)\n",
    "for c=1:length(sorted_draws)\n",
    "    s = 0.\n",
    "    for d=1:length(sorted_draws)\n",
    "        if sorted_draws[c][1] >= sorted_draws[d][1] && sorted_draws[c][2] >= sorted_draws[d][2]\n",
    "            s += 1.\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    MV_ECDF[sorted_draws[c]] = s/l_sorted_draws\n",
    "end\n",
    "\n",
    "sorted_draws = sort(draws,by=x->x[1])\n",
    "draws_ECDF = [MV_ECDF[c] for c in draws];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the number order of the polynomial expansions and hence the number of terms as well as the\n",
    "# dimension of the distribution\n",
    "\n",
    "n_th_order = 4\n",
    "n_variables = 2\n",
    "\n",
    "\n",
    "# Find all the combinatorical numbers needed to specify and create the polynomials\n",
    "bin_coef(n,k) = factorial(n)÷(factorial(k)*factorial(n - k))\n",
    "simplex_numbers(r,n) = bin_coef(n+r-1,r)\n",
    "x_medoid = [0.,0.]\n",
    "\n",
    "l_even_coefficients = [simplex_numbers(n_variables-1,c+1) for c=2:2:n_th_order]\n",
    "l_odd_coefficients = [simplex_numbers(n_variables-1,c+1) for c=1:2:n_th_order]\n",
    "\n",
    "n_even_coefficients = n_variables*sum(l_even_coefficients)\n",
    "n_odd_coefficients = n_variables*sum(l_odd_coefficients)\n",
    "\n",
    "multinomial_exponents = [[[r for r in k] for k in eachmultinomial(n_variables,n)] for n=1:n_th_order]\n",
    "multinomial_coefficients = [[multinomial(k) for k in eachmultinomial(n_variables,n)] for n=1:n_th_order];\n",
    "\n",
    "# Returns the constructed polynomial used for expansion\n",
    "function MV_param_expansion(x,a,parity,coef=multinomial_coefficients,expo=multinomial_exponents,expan=x_medoid)\n",
    "    a_i = 0\n",
    "    a_l = length(a)\n",
    "    x_l = length(x)\n",
    "    n = parity == 2 ? 0 : -1\n",
    "    s = 0.\n",
    "    while a_i < a_l\n",
    "        n += 2\n",
    "        for (i,k) in enumerate(expo[n])\n",
    "            a_i += 1\n",
    "            s += coef[n][i]*a[a_i]*prod([(x[c] - expan[c])^(k[c]) for c=1:x_l])\n",
    "        end\n",
    "    end\n",
    "            \n",
    "    return s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Functions for the pdf and CDF of the multivariate meta-gumbel distribution\n",
    "\n",
    "function gumbel_cdf(x,aμ,aβ)\n",
    "    μ = [MV_param_expansion(x,aμ[c,:],1) for c=1:size(aμ)[1]]\n",
    "    β = [MV_param_expansion(x,aβ[c,:],2) for c=1:size(aβ)[1]]\n",
    "    return exp(sum([-exp(-(x[c]-μ[c])/β[c]) for c=1:size(aμ)[1]]))\n",
    "end\n",
    "\n",
    "function gumbel_cdf(x,aμ=am,aβ=as)\n",
    "    μ = [MV_param_expansion(x,aμ[c,:],1) for c=1:size(aμ)[1]]\n",
    "    β = [MV_param_expansion(x,aβ[c,:],2) for c=1:size(aβ)[1]]\n",
    "    return exp(sum([-exp(-(x[c]-μ[c])/β[c]) for c=1:size(aμ)[1]]))\n",
    "end\n",
    "\n",
    "function gumbel_pdf(x,aμ,aβ)\n",
    "    μ = [MV_param_expansion(x,aμ[c,:],1) for c=1:size(aμ)[1]]\n",
    "    β = [MV_param_expansion(x,aβ[c,:],2) for c=1:size(aβ)[1]]\n",
    "    return exp(sum([-(x[c]-μ[c])/β[c]-exp(-(x[c]-μ[c])/β[c]) for c=1:size(aμ)[1]]))/(prod(β))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loss function used in the initial localisation of a feasibility region when optimising the fit\n",
    "\n",
    "function gumbel_feasible_loss(x,x_l=n_variables,n_ord=n_th_order,n_e=n_even_coefficients,n_o=n_odd_coefficients,l_e=l_even_coefficients,l_o=l_odd_coefficients)\n",
    "    \n",
    "    # Array of parameters for the coefficients on the β expansion \n",
    "    as = [x[(c-1)*(n_e ÷ 2) + d] for c=1:x_l, d=(n_o+1:(n_o+n_e ÷ 2))]\n",
    "    \n",
    "    eigenvalue_sum = 0\n",
    "    \n",
    "    cum_sum_even_coef = cumsum(l_e)\n",
    "    for c=1:size(as)[1]\n",
    "        order = 0\n",
    "        for d=0:length(cum_sum_even_coef)-1\n",
    "            order += 2\n",
    "            if d === 0\n",
    "                eigenvalue_sum += tensor_definiteness(as[c,1:cum_sum_even_coef[1]],x_l,order)\n",
    "            else\n",
    "                eigenvalue_sum += tensor_definiteness(as[c,cum_sum_even_coef[d]+1:cum_sum_even_coef[d+1]],x_l,order)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Returns the number of negative eigenvalues of the tensor representing the homogeneous polynomial\n",
    "    # of the β expansion\n",
    "    return eigenvalue_sum^2\n",
    "    \n",
    "end\n",
    "\n",
    "# Loss function used to fit the distribution to the empirical CDF of the data\n",
    "\n",
    "function gumbel_cdf_loss(x,Z=draws_ECDF,x_l=n_variables,n_ord=n_th_order,n_e=n_even_coefficients,n_o=n_odd_coefficients,l_e=l_even_coefficients,l_o=l_odd_coefficients)\n",
    "    \n",
    "    # Same first part as gumbel_feasible_loss to ensure that the optimisation algorithm doesn't leave\n",
    "    # a feasible region upon finding one while fitting the CDF\n",
    "    \n",
    "    as = [x[(c-1)*(n_e ÷ 2) + d] for c=1:x_l, d=(n_o+1:(n_o+n_e ÷ 2))]\n",
    "    \n",
    "    eigenvalue_sum = 0\n",
    "    \n",
    "    cum_sum_even_coef = cumsum(l_e)\n",
    "    for c=1:size(as)[1]\n",
    "        order = 0\n",
    "        for d=0:length(cum_sum_even_coef)-1\n",
    "            order += 2\n",
    "            if d === 0\n",
    "                eigenvalue_sum += tensor_definiteness(as[c,1:cum_sum_even_coef[1]],x_l,order)\n",
    "            else\n",
    "                eigenvalue_sum += tensor_definiteness(as[c,cum_sum_even_coef[d]+1:cum_sum_even_coef[d+1]],x_l,order)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if eigenvalue_sum > 0.\n",
    "        #println(100000*eigenvalue_sum^2)\n",
    "        return 100000*eigenvalue_sum^2\n",
    "    end\n",
    "    \n",
    "\n",
    "    L = length(x)\n",
    "    \n",
    "    am = [x[(c-1)*(n_o ÷ 2) + d] for c=1:x_l, d=1:(n_o ÷ 2)]\n",
    "\n",
    "    # Returns the square error between the empirical cdf and the current fit\n",
    "    res = sum(([gumbel_cdf(draws[c],am,as) for c=1:length(draws)] .- Z).^2)\n",
    "    return res\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniformly randomly generated initial point to begin the optimisation at\n",
    "x₀ = -1500 .+ rand(n_even_coefficients + n_odd_coefficients)*3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial optimisation to find a feasible region\n",
    "\n",
    "res = optimize(gumbel_feasible_loss, x₀, ParticleSwarm(n_particles = 15),\n",
    "                Optim.Options(iterations=12000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Number of negative eigenvalues in the β coefficient tensor: \"*string(sqrt(Optim.minimum(res))))\n",
    "initial_viable_point = Optim.minimizer(res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Optimisation of the metadistribution's CDF to the empirical CDF of the data\n",
    "\n",
    "res = optimize(gumbel_cdf_loss, initial_viable_point, ParticleSwarm(n_particles = 18),\n",
    "    Optim.Options(iterations=11000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square error between the empirical cdf and the current fit\n",
    "println(Optim.minimum(res))\n",
    "res_x = Optim.minimizer(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3.5\">Example of a $n = 200$ draw from a multivariate LogNormal distribution with </font>$\\mathbf{\\mu} = \\mathbf{0}$, \n",
    "$\\mathbf{\\Sigma} = \\begin{pmatrix}\n",
    "1 & 0.4\\\\\n",
    "0.4 & 1\n",
    "\\end{pmatrix}$\n",
    "\n",
    "![image](l_metalog_scatter.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form the arrays of coefficients used by gumbel_cdf and gumbel_pdf\n",
    "am = [res_x[(c-1)*(n_odd_coefficients ÷ 2) + d] for c=1:n_variables, d=1:(n_odd_coefficients ÷ 2)]\n",
    "as = [res_x[(c-1)*(n_even_coefficients ÷ 2) + d] for c=1:n_variables, d=(n_odd_coefficients+1:(n_odd_coefficients+n_even_coefficients ÷ 2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fitted CDF\n",
    "\n",
    "surface(0.01:0.01:5.,0.01:0.01:5.,(x,y)->gumbel_cdf([x,y],am,as),camera=(45, 65),legend=nothing,zlim=(0,1),xlabel=\"X\",ylabel=\"Y\",zlabel=\"F(x,y)\",c=:oslo)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
